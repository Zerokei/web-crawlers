{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫实验"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1-1.7 学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "response = urllib.request.urlopen('http://www.baidu.com')\n",
    "print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "data = bytes(urllib.parse.urlencode({'Chritch': '3200104207'}), encoding='utf8')\n",
    "response = urllib.request.urlopen('https://httpbin.org/post', data=data)\n",
    "print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "text = '''\n",
    "<html><body><div>\n",
    "<ul>\n",
    "<li class=\"0\"> first  </li>\n",
    "<li class=\"1\"> second </li>\n",
    "<li class=\"1\"> third  </li>\n",
    "<li class=\"0\"> fourth </li>\n",
    "</ul>\n",
    "</div></body></html>\n",
    "'''\n",
    "\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "text = '''\n",
    "<html><body><div>\n",
    "<ul>\n",
    "<li class=\"0\"> first  </li>\n",
    "<li class=\"1\"> second </li>\n",
    "<li class=\"1\"> third  </li>\n",
    "<li class=\"0\"> fourth </li>\n",
    "</ul>\n",
    "</div></body></html>\n",
    "'''\n",
    "\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[@class=\"0\"]')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree \n",
    "\n",
    "text = '''\n",
    "<html><body><div>\n",
    "<ul>\n",
    "<li class=\"0\"> first  </li>\n",
    "<li class=\"1\"> second </li>\n",
    "<li class=\"1\"> third  </li>\n",
    "<li class=\"0\"> fourth </li>\n",
    "</ul>\n",
    "</div></body></html>\n",
    "'''\n",
    "\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[@class=\"0\"]/text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree \n",
    "\n",
    "text = '''\n",
    "<html><body><div>\n",
    "<ul>\n",
    "<li class=\"0\"> first  </li>\n",
    "<li class=\"1\"> second </li>\n",
    "<li class=\"1\"> third  </li>\n",
    "<li class=\"0\"> fourth </li>\n",
    "</ul>\n",
    "</div></body></html>\n",
    "'''\n",
    "\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li')\n",
    "for item in result:\n",
    "    print(item.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 爬取猫眼电影 top100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.1 爬取 html\n",
    "因为猫眼电影近些年的反爬机制变严格了，故采取了一些比较特殊的手段\n",
    "\n",
    "- 根据文章指示，在谷歌浏览器调试模式下，copy as cURL(bash)，然后使用 curl-converter 转换成 python 代码\n",
    "- 注意：如果爬取的内容为输入验证信息，则需要现在浏览器中验证后，再重复上述步骤（保证没有被猫眼ban掉）\n",
    "- references\n",
    "    - https://blog.csdn.net/weixin_40340586/article/details/120134102\n",
    "    - https://curlconverter.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "cookies = {\n",
    "    '__mta': '217962025.1672026973241.1672052779855.1672052791315.27',\n",
    "    'uuid_n_v': 'v1',\n",
    "    'uuid': '3D291FD084D111EDBB2321DFA394E4C280D7CD55FEE54EFD943630063FB059E1',\n",
    "    '_csrf': '65bfbba146b96ab86c672c8aa5062a9350ff0a51eedbb3ce81a2af58b2c3ad96',\n",
    "    '_lxsdk_cuid': '181aa0bc24713-09a91303c0c072-26021a51-240000-181aa0bc248c8',\n",
    "    '_lxsdk': '3D291FD084D111EDBB2321DFA394E4C280D7CD55FEE54EFD943630063FB059E1',\n",
    "    'Hm_lvt_703e94591e87be68cc8da0da7cbd0be2': '1672026972',\n",
    "    '__mta': '142375437.1672026977996.1672026977996.1672026977996.1',\n",
    "    'Hm_lpvt_703e94591e87be68cc8da0da7cbd0be2': '1672052791',\n",
    "    '_lxsdk_s': '1854e1b83af-6b6-637-298%7C%7C11',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'Accept-Language': 'zh,zh-TW;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    # 'Cookie': '__mta=217962025.1672026973241.1672052779855.1672052791315.27; uuid_n_v=v1; uuid=3D291FD084D111EDBB2321DFA394E4C280D7CD55FEE54EFD943630063FB059E1; _csrf=65bfbba146b96ab86c672c8aa5062a9350ff0a51eedbb3ce81a2af58b2c3ad96; _lxsdk_cuid=181aa0bc24713-09a91303c0c072-26021a51-240000-181aa0bc248c8; _lxsdk=3D291FD084D111EDBB2321DFA394E4C280D7CD55FEE54EFD943630063FB059E1; Hm_lvt_703e94591e87be68cc8da0da7cbd0be2=1672026972; __mta=142375437.1672026977996.1672026977996.1672026977996.1; Hm_lpvt_703e94591e87be68cc8da0da7cbd0be2=1672052791; _lxsdk_s=1854e1b83af-6b6-637-298%7C%7C11',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "    'sec-ch-ua': '\"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"108\", \"Google Chrome\";v=\"108\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "}\n",
    "\n",
    "\n",
    "pages = []\n",
    "for i in range(10):\n",
    "    # 使用 cookies 以绕过猫眼的验证，offset为当前页的第一部电影排名\n",
    "    response = requests.get('https://www.maoyan.com/board/4?offset={}'.format(i*10), cookies=cookies, headers=headers)\n",
    "    pages.append(response.text)\n",
    "    print(\"已获取第{}页\".format(i+1))\n",
    "    # 间隔 3 秒时间，防止过于频繁\n",
    "    time.sleep(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果没有加上 cookie，我们获得的内容如下所示\n",
    "    \n",
    "```python\n",
    "<!DOCTYPE html><html lang=en><head><meta charset=utf-8><link href=//p0.meituan.net rel=dns-prefetch><link href=//p1.meituan.net rel=dns-prefetch><link href=//s3plus.meituan.net rel=dns-prefetch><title>猫眼验证中心</title><meta name=keywords content=\"猫眼验证中心\"><meta name=description content=\"猫眼验证中心\"><meta name=applicable-device content=mobile><meta name=viewport content=\"width=device-width,initial-scale=1,user-scalable=no\"><meta name=format-detection content=\"telephone=no\"><meta name=format-detection content=\"address=no\"><meta name=for content=maoyan.com><link rel=icon href=https://e.pipi.cn/overseas/faviconmy.ico type=image/x-icon><script src=https://e.pipi.cn/overseas/polyfill.min.js></script><script>var AppData= {\"redirectUrl\":\"\",\"domain\":\"\",\"project\":\"verify\",\"env\":\"prod\"}</script><script crossorigin=anonymous src=//www.dpfile.com/app/owl/static/owl_latest.js></script><script>\"use strict\";!function(){var e=0<arguments.length&&void 0!==arguments[0]?arguments[0]:\"_Owl_\",t=window;t[e]||(t[e]={isRunning:!1,isReady:!1,preTasks:[],dataSet:[],pageData:[],disableMutaObserver:!1,observer:null,use:function(e,i){this.isReady&&t.Owl&&t.Owl[e](i),this.preTasks.push({api:e,data:[i]})},add:function(e){this.dataSet.push(e)},run:function(){var e=this;if(!this.isRunning){this.isRunning=!0;var i=t.onerror;t.onerror=function(){this.isReady||this.add({type:\"jsError\",data:arguments}),i&&i.apply(t,arguments)}.bind(this),(t.addEventListener||t.attachEvent)(\"error\",(function(t){e.isReady||e.add({type:\"resError\",data:[t]})}),!0);var r=window.MutationObserver||window.WebKitMutationObserver||window.MozMutationObserver,n=window.performance||window.WebKitPerformance;if(r&&n){var s=-1,a=window.navigator.userAgent;if(-1<a.indexOf(\"compatible\")&&-1<a.indexOf(\"MSIE\")?(new RegExp(\"MSIE (\\\\d+\\\\.\\\\d+);\").test(a),s=parseFloat(RegExp.$1)):-1<a.indexOf(\"Trident\")&&-1<a.indexOf(\"rv:11.0\")&&(s=11),-1!==s&&s<=11)return void(this.disableMutaObserver=!0);try{this.observer=new r((function(t){e.pageData.push({mutations:t,startTime:n.now()})})),this.observer.observe(document,{childList:!0,subtree:!0})}catch(i){console.log(\"mutationObserver err\")}}else this.disableMutaObserver=!0}}},t[e].run())}()</script><script crossorigin=anonymous src=https://obj.pipi.cn/festatic/basicdata_mac/md/yao-0.0.10.js></script><script>Yao.start({project:\"yamaha\",page:{sample:1}})</script><script>var isDevMode=JSON.parse(\"false\")</script><script>Owl.start({project:\"com.sankuai.movie.security.yamaha\",pageUrl:location.origin+location.pathname,resource:{},devMode:isDevMode,autoCatch:{console:!0}})</script><link href=/yamaha/public/css/verify.07561394.css rel=stylesheet></head><body><div id=app></div><script src=//s0.meituan.net/bs/knb/v1.8.3/knb.js crossorigin=anonymous></script><script type=text/javascript src=/yamaha/public/js/verify.83983a.js></script></body></html>\n",
    "```\n",
    "\n",
    "但是在这之上加了 cookie 也没用。\n",
    "在浏览器登陆过后，不加 cookie 也可以正常使用\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.2 提取 top100 电影信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "top_movies = [] \n",
    "\n",
    "def extract_element(text):\n",
    "    print(text)\n",
    "    html = etree.HTML(text)\n",
    "    # 提取各种元素\n",
    "    numbers = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/i/text()')\n",
    "    movies = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p/a/text()')\n",
    "    stars = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"star\"]/text()')\n",
    "    releasetimes = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"releasetime\"]/text()')\n",
    "    scores_interger = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"score\"]/i[@class=\"integer\"]/text()')\n",
    "    scores_fraction = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"score\"]/i[@class=\"fraction\"]/text()')\n",
    "    for i in range(10):\n",
    "        movie = []\n",
    "        movie.append(numbers[i])\n",
    "        movie.append(movies[i])\n",
    "        movie.append(stars[i].replace('\\n', '').strip())\n",
    "        movie.append(releasetimes[i])\n",
    "        movie.append(scores_interger[i] + scores_fraction[i])\n",
    "        # 加入top movies列表中\n",
    "        top_movies.append(movie)\n",
    "\n",
    "# 解析1-10页的内容\n",
    "for i in range(10):\n",
    "    extract_element(pages[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.3 输出到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('top_100.txt', 'w').close()\n",
    "for i in range(100):\n",
    "    with open('top_100.txt', 'a') as f:\n",
    "        print(top_movies[i], file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整合\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from lxml import etree\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.76',\n",
    "}\n",
    "\n",
    "pages = []  # 存储每一页的 HTML\n",
    "top_movies = []  # 从 HTML 中提取数据\n",
    "\n",
    "def set_pages():\n",
    "    for i in range(10):\n",
    "        response = requests.get('https://www.maoyan.com/board/4?offset={}'.format(i * 10), headers=headers)\n",
    "        pages.append(response.text)\n",
    "        print(\"已获取第{}页\".format(i + 1))\n",
    "        # 间隔 3 秒时间，防止过于频繁\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "def extract_data():\n",
    "    for i in range(10):\n",
    "        extract_element(pages[i])\n",
    "\n",
    "\n",
    "def extract_element(text):\n",
    "    # print(text)\n",
    "    html = etree.HTML(text)\n",
    "    # 提取各种元素\n",
    "    numbers = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/i/text()')\n",
    "    movies = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p/a/text()')\n",
    "    stars = html.xpath('//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"star\"]/text()')\n",
    "    releasetimes = html.xpath(\n",
    "        '//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"releasetime\"]/text()')\n",
    "    scores_interger = html.xpath(\n",
    "        '//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"score\"]/i[@class=\"integer\"]/text()')\n",
    "    scores_fraction = html.xpath(\n",
    "        '//div[@class=\"content\"]/div/div/dl/dd/div/div/div/p[@class=\"score\"]/i[@class=\"fraction\"]/text()')\n",
    "    for i in range(10):\n",
    "        movie = []\n",
    "        movie.append(numbers[i])\n",
    "        movie.append(movies[i])\n",
    "        movie.append(stars[i].replace('\\n', '').strip())\n",
    "        movie.append(releasetimes[i])\n",
    "        movie.append(scores_interger[i] + scores_fraction[i])\n",
    "        # 加入top movies列表中\n",
    "        top_movies.append(movie)\n",
    "\n",
    "\n",
    "def save_data():\n",
    "    open('top_100.txt', 'w').close()\n",
    "    for i in range(100):\n",
    "        with open('top_100.txt', 'a', encoding='utf-8')as f:\n",
    "            print(top_movies[i], file=f)\n",
    "\n",
    "\n",
    "def main():\n",
    "    set_pages()\n",
    "    extract_data()\n",
    "    save_data()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 OCR 识别"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装 tesserocr 的库时，可能需要一些库支持\n",
    "```bash\n",
    "$ sudo apt install libleptonica-dev libtesseract-dev tesseract-ocr{,-eng,-osd}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tesserocr\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image = Image.open('checkcode.png')\n",
    "\n",
    "# 处理图像\n",
    "image = image.convert('L')\n",
    "threshold = 150 # 设置滤波上限\n",
    "table = []\n",
    "for i in range(256):\n",
    "    if i < threshold:\n",
    "        table.append(0)\n",
    "    else:\n",
    "        table.append(1)\n",
    "image = image.point(table, '1')\n",
    "\n",
    "# plt.imshow(image)\n",
    "result = tesserocr.image_to_text(image)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 爬取起点中文网免费小说"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml import etree\n",
    "import requests\n",
    "import urllib\n",
    "import random\n",
    "import time\n",
    "import random\n",
    "def get_ua():\n",
    "    return 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'\n",
    "\n",
    "def get_html(url):\n",
    "\n",
    "    headers = {\n",
    "        'Referer': 'https://book.qidian.com/',\n",
    "        'User-Agent': get_ua(),\n",
    "    }\n",
    "\n",
    "\n",
    "    try: \n",
    "        res = requests.get(url,headers=headers, timeout=(1,0.5))\n",
    "        try:\n",
    "            res.raise_for_status()\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'Error: {err}')\n",
    "        else: \n",
    "            print('Success!')\n",
    "        return res.text\n",
    "    except:\n",
    "        print(res.text)\n",
    "        print(\"爬取超时\")\n",
    "# 输入小说的第一章\n",
    "url = 'https://read.qidian.com/chapter/0mNMNoFQxR3bhZU9AFSCzA2/RqJBDW3NgsP4p8iEw--PPw2/'\n",
    "\n",
    "pages = []\n",
    "for i in range(30):\n",
    "    print(\"爬取第{}章\".format(i+1))\n",
    "    res = get_html(url)\n",
    "    html = etree.HTML(res)\n",
    "    pages.append(html)\n",
    "    url = \"https:{}\".format(html.xpath('//*[@id=\"j_chapterNext\"]/@href')[0])\n",
    "    print(\"获取链接：{}\".format(url))\n",
    "    time.sleep(random.random())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "open('novel.txt', 'w').close()\n",
    "for html in pages:\n",
    "    text = html.xpath('//div[@class=\"read-content j_readContent\"]/p/text()')\n",
    "    for line in text:\n",
    "        with open('novel.txt', 'a') as f:\n",
    "            print(line, file=f)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遇到的问题及解决方案：\n",
    "- 被识别出是脚本 -> 添加 headers，模拟浏览器\n",
    "- 单一 headers 容易被 ban -> 随机 headers 元素\n",
    "- 动态加载的主页 -> 采用访问第一页，然后顺序向后索引的方式\n",
    "- 获取的html和原有的html内容不一致 -> 参考获取的 html 页内容"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
