{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "cList = []\n",
    "target_url = \"https://www.huixx.cn/sai/match/index/profession/1/province/0/foreign/0/process/0/obj/0\"\n",
    "\n",
    "pageMax = 2;  # 爬几页\n",
    "\n",
    "\n",
    "def get_huixx_cookie():\n",
    "    f = open(\"./tmp/_huixx.cn_cookie.tmp\", \"r\")\n",
    "    ck = f.read()\n",
    "    f.close()\n",
    "    return ck\n",
    "\n",
    "\n",
    "head = {\n",
    "    'Cookie': get_huixx_cookie(),\n",
    "}\n",
    "\n",
    "s = requests.session()\n",
    "\n",
    "\n",
    "class CInfo:\n",
    "    def __init__(self, url, name, sTime, cTime, status):\n",
    "        self.url = \"https://www.huixx.cn\" + url.strip()  # info msg url\n",
    "        self.name = name.strip()  # competition name\n",
    "        self.sTime = sTime  # sign up time\n",
    "        self.cTime = cTime  # competing time\n",
    "        # self.status = status.strip()                                    # competition status\n",
    "        self.source = ''\n",
    "        try:\n",
    "            self.source = requests.get(self.url, headers=head).text  # get info msg\n",
    "        except requests.exceptions.ConnectTimeout or requests.exceptions.ProxyError:\n",
    "            print(\"Cinfo url\" + str(url) + \"Error\")\n",
    "        self.bsobj = BeautifulSoup(self.source, features=\"lxml\")\n",
    "        self.details = self.bsobj.find_all(is_details)\n",
    "\n",
    "    def printMe(self):\n",
    "        print(self.url, end=\"\\n\")\n",
    "        print(self.name, end=\"\\n\")\n",
    "        print(self.sTime, end=\"\\n\")\n",
    "        print(self.cTime, end=\"\\n\")\n",
    "        print(self.status, end=\"\\n\")\n",
    "        print(self.details[0], end=\"\\n\")\n",
    "        print(self.details[1], end=\"\\n\")\n",
    "\n",
    "\n",
    "def is_details(tag):\n",
    "    return tag.has_attr('class') and tag['class'] == [\"bg-ff\", \"pl-30\", \"pr-30\", \"pt-20\", \"pb-25\", \"mb-20\", \"rich_text\"]\n",
    "\n",
    "\n",
    "def is_competition_record(tag):\n",
    "    return tag.has_attr('class') and tag['class'] == [\"bor_bda\", \"pl-5\"]\n",
    "\n",
    "\n",
    "def getLastUpdTime():\n",
    "    f = open('./tmp/_huixx.cn_.tmp', 'r')\n",
    "    time = f.read()\n",
    "    f.close()\n",
    "    return time\n",
    "\n",
    "\n",
    "def updUpdTime(time):\n",
    "    f = open(\"./tmp/_huixx.cn_.tmp\", 'w')\n",
    "    f.write(time)\n",
    "    f.close()\n",
    "    return\n",
    "\n",
    "\n",
    "def main():\n",
    "    lastUpdTime = getLastUpdTime()\n",
    "    newUpdTime = lastUpdTime\n",
    "    # initialize POST body\n",
    "    # 初始化 POST 请求体\n",
    "    body = []\n",
    "    for i in range(pageMax):\n",
    "        body.append({'profession_arr[]': '1', 'page': str(i + 1)})\n",
    "\n",
    "    try:\n",
    "        resp = s.get(target_url, headers=head)\n",
    "    except requests.exceptions.ConnectTimeout or requests.exceptions.ProxyError or requests.exceptions.ConnectionError:\n",
    "        print(\"Error, check the proxy first, then contact the software team\")\n",
    "    for i in range(pageMax):\n",
    "        try:\n",
    "            resp = s.post(target_url, headers=head, data=body[i])\n",
    "        except requests.exceptions.ConnectTimeout or requests.exceptions.ProxyError or requests.exceptions.ConnectionError:\n",
    "            print(\"Error, check the proxy first, then contact the software team\")\n",
    "        jsonStr = json.loads(resp.text[71:]).get('data').get('list')\n",
    "        for j in range(15):  # 一页有十五项\n",
    "            updTime = ''\n",
    "            url = name = sTime = cTime = status = \"\"\n",
    "\n",
    "            updTime = jsonStr[j].get('update_time')\n",
    "\n",
    "            if updTime < lastUpdTime:\n",
    "                continue\n",
    "\n",
    "            if updTime > newUpdTime:\n",
    "                newUpdTime = updTime\n",
    "\n",
    "            url = \"/match_\" + str(jsonStr[j].get('id'))\n",
    "            name = jsonStr[j].get('name')\n",
    "            status = str(jsonStr[j].get('process_name'))\n",
    "            sTime = [str(jsonStr[j].get('start_pre_time')).strip(), str(jsonStr[j].get('end_pre_time')).strip()]\n",
    "            cTime = [str(jsonStr[j].get('start_time')).strip(), str(jsonStr[j].get('end_time')).strip()]\n",
    "            newCmpt = CInfo(url, name, sTime, cTime, status)\n",
    "            cList.append(newCmpt)  # 所有比赛信息都在该 list 中\n",
    "\n",
    "            # newCmpt.printMe()           # 打印比赛信息\n",
    "    updUpdTime(newUpdTime)\n",
    "    with open(\"./tmp/_huixx.cn_.json\", 'w') as f:\n",
    "        json.dump(cList, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
